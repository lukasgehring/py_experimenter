{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLnG0-_UC6ig"
   },
   "source": [
    "# Welcome to this PyExperimenter example for conditional parameter grids!\n",
    "\n",
    "This example shows the usage of `PyExperimenter` with a conditional parameter grid. We will programmatically define the parameter combinations of a support vector machine, instead of generating the entire cartesian product from the parameters defined in the config file.  \n",
    "\n",
    "To execute this notebook you need to install:\n",
    "```\n",
    "pip install py_experimenter\n",
    "pip install scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkmxwSl8DW-V"
   },
   "source": [
    "# Experiment Configuration File\n",
    "This notebook is based on the execution of the `PyExperimenter` based on a configuration file. Different aspects of this file are explained in the `README` file in the [repository](https://github.com/tornede/py_experimenter). Here, we do not set the parameter values in the config file, as we will create the parameter grid programmatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmyy_sAuBCaG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "content = \"\"\"\n",
    "[PY_EXPERIMENTER]\n",
    "provider = sqlite \n",
    "database = svm_db_example\n",
    "table = svm_experiment_example\n",
    "\n",
    "cpu.max = 5 \n",
    "\n",
    "keyfields = dataset, cross_validation_splits:int, seed:int, kernel, gamma:DECIMAL, degree:int, coef0:DECIMAL\n",
    "\n",
    "resultfields = train_f1:DECIMAL, train_accuracy:DECIMAL, test_f1:DECIMAL, test_accuracy:DECIMAL\n",
    "resultfields.timestamps = false\n",
    "\n",
    "[CUSTOM] \n",
    "path = sample_data\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join('config', 'configuration_cond.cfg'), \"w\") as f: \n",
    "  f.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5pjc0TMBjnr"
   },
   "source": [
    "# Defining the execution function\n",
    "\n",
    "Next, the execution of a single experiment has to be defined. Note that this is a dummy example, which contains limited reasonable code. It is meant to show the core functionality of the PyExperimenter. \n",
    "\n",
    "The method is called with the parameters, i.e. `keyfields`, of a database entry. The results are meant to be processed to be written into the database, i.e. as `resultfields`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHr-IN2gBe8V"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from py_experimenter.experimenter import PyExperimenter\n",
    "from py_experimenter.result_processor import ResultProcessor\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def run_svm(parameters: dict, result_processor: ResultProcessor, custom_config: dict):\n",
    "    sleep(randint(0,5))\n",
    "    seed = parameters['seed']\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    data = load_iris()\n",
    "\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "\n",
    "    # Create Support Vector Machine with parameters dependent on the kernel\n",
    "    kernel = parameters['kernel']\n",
    "    if kernel == 'linear':\n",
    "        svc = SVC(kernel=parameters['kernel'])\n",
    "    elif kernel == 'poly':\n",
    "        svc = SVC(kernel=parameters['kernel'], gamma=parameters['gamma'], coef0=parameters['coef0'], degree=parameters['degree'])\n",
    "    elif kernel == 'rbf':\n",
    "        svc = SVC(kernel=parameters['kernel'], gamma=parameters['gamma'])\n",
    "\n",
    "    svc = SVC()\n",
    "\n",
    "    model = make_pipeline(StandardScaler(), svc)  \n",
    "\n",
    "    if parameters['dataset'] != 'iris':\n",
    "        raise ValueError(\"Example error\")\n",
    "\n",
    "    scores = cross_validate(model, X, y, cv=parameters['cross_validation_splits'],\n",
    "        scoring=('accuracy', 'f1_micro'),\n",
    "        return_train_score=True)\n",
    "    \n",
    "    resultfields = {'train_f1': np.mean(scores['train_f1_micro']),\n",
    "                'train_accuracy': np.mean(scores['train_accuracy'])}\n",
    "    result_processor.process_results(resultfields)\n",
    "\n",
    "    resultfields = {'test_f1': np.mean(scores['test_f1_micro']),\n",
    "                'test_accuracy': np.mean(scores['test_accuracy'])}\n",
    "    result_processor.process_results(resultfields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sa6mN98NBua-"
   },
   "source": [
    "# Executing PyExperimenter\n",
    "\n",
    "The actual execution of the PyExperimenter is done in multiple steps. \n",
    "\n",
    "## Initialize PyExperimenter\n",
    "The PyExperimenter is initialized with the previously created configuration file. Additionally, the `PyExperimenter` is given a `name`, i.e. job id, which is especially useful for parallel executions of multiple experiments on HPC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFdaTyYQ-yqa"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from py_experimenter.experimenter import PyExperimenter\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "experimenter = PyExperimenter(config_file=os.path.join('config', 'configuration_cond.cfg'), name=\"SVM_experimenter_01\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdLXOI7eFhBh"
   },
   "source": [
    "## Fill Table\n",
    "\n",
    "The table is filled programmatically using the  `fill_table_from_combination()` method. We first generate the fixed parameter combinations for each kernel of the SVM in the first three lines.\n",
    "* For the `rbf` kernel, we need to set values for the `gamma` parameter. The degree and `coef0` parameter are not present in this kernel, so we set these to `'nan'`.\n",
    "* For the `poly` kernel, we need to set the `gamma`, the degree as well as the `coef0` parameter.\n",
    "* For the `linear` kernel, we do not need to set any parameters, so all of them are set to `'nan'`.\n",
    "\n",
    "Afterwards, we combine these with the seed, the dataset and the cross_validation_splits parameters, which are present for all experiment runs. Thus, these are not set unconditionally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdLXOI7eFhBh"
   },
   "source": [
    " \n",
    "\n",
    "Note that the table can easily be obtained as `pandas.Dataframe` via `experimenter.get_table()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "5DJlSHO3-2-v",
    "outputId": "447580e6-6a16-42ca-c44b-48a12829af91"
   },
   "outputs": [],
   "source": [
    "# Create parameter configurations for each kernel\n",
    "combinations = [{'kernel': 'rbf', 'gamma': gamma, 'degree':'nan', 'coef0':'nan'} for gamma in ['0.1','0.3']]\n",
    "combinations += [{'kernel': 'poly', 'gamma': gamma, 'degree': degree, 'coef0': coef0} for gamma in ['0.1','0.3'] for degree in ['3','4'] for coef0 in ['0.0', '0.1']]\n",
    "combinations += [{'kernel': 'linear','gamma': 'nan', 'degree':'nan', 'coef0':'nan'}]\n",
    "\n",
    "# Fill experimenter\n",
    "experimenter.fill_table_from_combination(parameters={'seed': ['1', '2', '3', '4', '5'], \n",
    "'dataset': ['iris'],\n",
    "'cross_validation_splits': ['5'] },\n",
    "fixed_parameter_combinations=combinations)\n",
    "\n",
    "# showing database table\n",
    "experimenter.get_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMGyvpTqFklu"
   },
   "source": [
    "## Execute PyExperimenter\n",
    "All experiments are executed one after the other by the same `PyExperimenter` due to `max_experiments=-1`. If just a single one or a predifined number of experiments should be executed, the `-1` has to be replaced by the according amount. The `random_order` is especially important in case of parallel execution of multiple `PyExperimenter`, e.g. when doing it on a HPC, to avoid collusions of accessing the same row of the table. \n",
    "\n",
    "The first parameter, i.e. `run_svm`, relates to the actual method that should be executed with the given keyfields of the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cDsuIw4M_AyY",
    "outputId": "d242da6f-1c9e-421b-f916-694c1a98ba95"
   },
   "outputs": [],
   "source": [
    "experimenter.execute(run_svm, max_experiments=-1, random_order=True)\n",
    "\n",
    "# showing database table\n",
    "experimenter.get_table() "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "70747bb7517347330a9c916afd85b93cf043b7403e40b7449b044e4a912a148a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
