{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "iLnG0-_UC6ig"
			},
			"source": [
				"# General Usage\n",
				"\n",
				"This example shows the general usage of `PyExperimenter`, from creating an experiment configuration file, over the actual execution of (dummy) experiments, to the extraction of experimental results. \n",
				"\n",
				"To execute this notebook you need to install:\n",
				"```\n",
				"pip install py_experimenter\n",
				"pip install scikit-learn\n",
				"```"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "qkmxwSl8DW-V"
			},
			"source": [
				"## Experiment Configuration File\n",
				"This notebook about the execution of the `PyExperimenter` based on a configuration file. Different aspects of this file are explained in the `README` file in the [repository](https://github.com/tornede/py_experimenter).\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"id": "fmyy_sAuBCaG"
			},
			"outputs": [],
			"source": [
				"import os\n",
				"\n",
				"content = \"\"\"\n",
				"[PY_EXPERIMENTER]\n",
				"provider = sqlite \n",
				"database = automl_conf_2023\n",
				"table = best_paper_table \n",
				"\n",
				"keyfields = dataset, cross_validation_splits:int, seed:int, kernel\n",
				"dataset = iris\n",
				"cross_validation_splits = 5\n",
				"seed = 2:6:2 \n",
				"kernel = linear, poly, rbf, sigmoid\n",
				"\n",
				"resultfields = pipeline:LONGTEXT, train_f1:DECIMAL, train_accuracy:DECIMAL, test_f1:DECIMAL, test_accuracy:DECIMAL\n",
				"resultfields.timestamps = false\n",
				"\n",
				"[CUSTOM] \n",
				"path = sample_data\n",
				"\"\"\"\n",
				"experiment_configuration_file_path = os.path.join('config', 'example_general_usage.cfg')\n",
				"with open(experiment_configuration_file_path, \"w\") as f: \n",
				"  f.write(content)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "b5pjc0TMBjnr"
			},
			"source": [
				"## Defining the execution function\n",
				"\n",
				"Next, the execution of a single experiment has to be defined. Note that this is a dummy example, which contains limited reasonable code. It is meant to show the core functionality of the PyExperimenter. \n",
				"\n",
				"The method is called with the parameters, i.e. `keyfields`, of a database entry. The results are meant to be processed to be written into the database, i.e. as `resultfields`. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"id": "gHr-IN2gBe8V"
			},
			"outputs": [],
			"source": [
				"import random\n",
				"import numpy as np\n",
				"\n",
				"from py_experimenter.result_processor import ResultProcessor\n",
				"\n",
				"from sklearn.datasets import load_iris\n",
				"from sklearn.pipeline import make_pipeline\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"from sklearn.svm import SVC\n",
				"from sklearn.model_selection import cross_validate\n",
				"\n",
				"def run_ml(parameters: dict, result_processor: ResultProcessor, custom_config: dict):\n",
				"  seed = parameters['seed']\n",
				"  random.seed(seed)\n",
				"  np.random.seed(seed)\n",
				"\n",
				"  data = load_iris()\n",
				"  # In case you want to load a file from a path\n",
				"  # path = os.path.join(custom_config['path'], parameters['dataset'])\n",
				"  # data = pd.read_csv(path)\n",
				"\n",
				"  X = data.data\n",
				"  y = data.target\n",
				"\n",
				"  model = make_pipeline(StandardScaler(), SVC(kernel=parameters['kernel'], gamma='auto'))  \n",
				"  result_processor.process_results({\n",
				"    'pipeline': str(model)\n",
				"  })\n",
				"\n",
				"  if parameters['dataset'] != 'iris':\n",
				"    raise ValueError(\"Example error\")\n",
				"\n",
				"  scores = cross_validate(model, X, y, \n",
				"    cv=parameters['cross_validation_splits'],\n",
				"    scoring=('accuracy', 'f1_micro'),\n",
				"    return_train_score=True\n",
				"  )\n",
				"  \n",
				"  result_processor.process_results({\n",
				"    'train_f1': np.mean(scores['train_f1_micro']),\n",
				"    'train_accuracy': np.mean(scores['train_accuracy'])\n",
				"  })\n",
				"\n",
				"  result_processor.process_results({\n",
				"    'test_f1': np.mean(scores['test_f1_micro']),\n",
				"    'test_accuracy': np.mean(scores['test_accuracy'])\n",
				"  })"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "Sa6mN98NBua-"
			},
			"source": [
				"## Executing PyExperimenter\n",
				"\n",
				"The actual execution of the PyExperimenter is done in multiple steps. \n",
				"\n",
				"### Initialize PyExperimenter\n",
				"The PyExperimenter is initialized with the previously created configuration file. Additionally, the `PyExperimenter` is given a `name`, i.e. job id, which is especially useful for parallel executions of multiple experiments on HPC. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"id": "EFdaTyYQ-yqa"
			},
			"outputs": [],
			"source": [
				"from py_experimenter.experimenter import PyExperimenter\n",
				"\n",
				"experimenter = PyExperimenter(experiment_configuration_file_path=experiment_configuration_file_path, name='example_notebook')"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "tdLXOI7eFhBh"
			},
			"source": [
				"### Fill Table\n",
				"\n",
				"The table is filled based on the above created configuration file with `fill_table_from_config()`. Therefore, the cartesian product of all keyfields makes up the content of the table. Additionally, a custom defined row, i.e. a custom defined keyfield tuple, is added with `fill_table_with_rows()`. \n",
				"\n",
				"Note that the table can easily be obtained as `pandas.Dataframe` via `experimenter.get_table()`."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 457
				},
				"id": "5DJlSHO3-2-v",
				"outputId": "447580e6-6a16-42ca-c44b-48a12829af91"
			},
			"outputs": [],
			"source": [
				"experimenter.fill_table_from_config()\n",
				"\n",
				"experimenter.fill_table_with_rows(rows=[\n",
				"      {'dataset': 'new_data', 'cross_validation_splits': 3, 'seed': 42, 'kernel':'linear'}])\n",
				"\n",
				"# showing database table\n",
				"experimenter.get_table()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "jMGyvpTqFklu"
			},
			"source": [
				"### Execute PyExperimenter\n",
				"All experiments are executed one after the other by the same `PyExperimenter` due to `max_experiments=-1`. If just a single one or a predifined number of experiments should be executed, the `-1` has to be replaced by the according amount. The `random_order` is especially important in case of parallel execution of multiple `PyExperimenter`, e.g. when doing it on a HPC, to avoid collusions of accessing the same row of the table. \n",
				"\n",
				"The first parameter, i.e. `run_ml`, relates to the actual method that should be executed with the given keyfields of the table. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 1000
				},
				"id": "cDsuIw4M_AyY",
				"outputId": "d242da6f-1c9e-421b-f916-694c1a98ba95"
			},
			"outputs": [],
			"source": [
				"experimenter.execute(run_ml, max_experiments=-1, random_order=True)\n",
				"\n",
				"# showing database table\n",
				"experimenter.get_table() "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "ivljpd70Fnal"
			},
			"source": [
				"### Restart Failed Experiments\n",
				"\n",
				"As experiments fail at some time, those experiments were reset for another try with `reset_experiments()`. The `status` describes which table rows should be replace. In this example all failed experiments, i.e. having `status==error`, are reset."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 955
				},
				"id": "3Ndelh6I_EXH",
				"outputId": "2eba52e5-2794-4ff7-ccc2-d2bfcf32b4d9"
			},
			"outputs": [],
			"source": [
				"experimenter.reset_experiments(status='error')\n",
				"\n",
				"# showing database table\n",
				"experimenter.get_table() "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "oLgmbd75Jtwm"
			},
			"source": [
				"After the reset of failed experiments, they can be executed again as described above. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 1000
				},
				"id": "_lH7S235Amhk",
				"outputId": "8c316569-b05f-4ceb-ff84-058e57613b4c"
			},
			"outputs": [],
			"source": [
				"experimenter.execute(run_ml, max_experiments=-1, random_order=True)\n",
				"\n",
				"# showing database table\n",
				"experimenter.get_table() "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "ekECNVPGJxyH"
			},
			"source": [
				"### Generating Result Table\n",
				"\n",
				"\n",
				"The table containes single experiment results. Those can be aggregated, e.g. to generate the mean over all seeds. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 143
				},
				"id": "gNwR26PcVZQK",
				"outputId": "c8fb7af2-25ad-4882-d4ae-9fb7ada92d36"
			},
			"outputs": [],
			"source": [
				"result_table_agg = experimenter.get_table().groupby(['dataset']).mean()\n",
				"result_table_agg"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "bjp-_uRDJ7oB"
			},
			"source": [
				"### Printing LaTex Table\n",
				"\n",
				"As `pandas.Dataframe`s can easily be printed as LaTex table, here is an example code for one of the above result columns. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "lMdk41hFV69U",
				"outputId": "995a326a-ad5c-40f4-e5bc-3f54e3dd5a60"
			},
			"outputs": [],
			"source": [
				"print(result_table_agg.to_latex(columns=['test_f1'], index_names=['dataset']))"
			]
		}
	],
	"metadata": {
		"colab": {
			"collapsed_sections": [],
			"provenance": []
		},
		"kernelspec": {
			"display_name": "Python 3.9.13 ('py_experimenter')",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.13"
		},
		"vscode": {
			"interpreter": {
				"hash": "30b9efe2289cd36b652894ab0bd923e43e4bb246ae321ab1cccf8b0afec1ce5f"
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 0
}
