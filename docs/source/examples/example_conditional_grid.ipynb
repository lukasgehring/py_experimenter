{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "iLnG0-_UC6ig"
			},
			"source": [
				"# Conditional Parameter Grids\n",
				"\n",
				"This example shows the usage of `PyExperimenter` with a conditional parameter grid. We will programmatically define the parameter combinations of a support vector machine, instead of generating the entire cartesian product from the parameters defined in the config file.  \n",
				"\n",
				"To execute this notebook you need to install:\n",
				"```\n",
				"pip install py_experimenter\n",
				"pip install scikit-learn\n",
				"```"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "qkmxwSl8DW-V"
			},
			"source": [
				"## Experiment Configuration File\n",
				"This notebook shows an example execution of `PyExperimenter` based on an experiment configuration file. Further explanation about the usage of `PyExperimenter` can be found in the [documentation](https://tornede.github.io/py_experimenter/usage.html). Here, we only define keyfields and resultfields and do not set the parameter values in the experiment configuration file as we will create the parameter grid programmatically."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"id": "fmyy_sAuBCaG"
			},
			"outputs": [],
			"source": [
				"import os\n",
				"\n",
				"content = \"\"\"\n",
				"[PY_EXPERIMENTER]\n",
				"provider = sqlite \n",
				"database = py_experimenter\n",
				"table = svm_experiment_example\n",
				"\n",
				"keyfields = dataset, cross_validation_splits:int, seed:int, kernel, gamma:DECIMAL, degree:int, coef0:DECIMAL\n",
				"\n",
				"resultfields = train_f1:DECIMAL, train_accuracy:DECIMAL, test_f1:DECIMAL, test_accuracy:DECIMAL\n",
				"resultfields.timestamps = false\n",
				"\n",
				"[CUSTOM] \n",
				"path = sample_data\n",
				"\"\"\"\n",
				"experiment_configuration_file_path = os.path.join('config', 'example_conditional_grid.cfg')\n",
				"with open(experiment_configuration_file_path, \"w\") as f: \n",
				"  f.write(content)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "b5pjc0TMBjnr"
			},
			"source": [
				"## Defining the execution function\n",
				"\n",
				"Next, the execution of a single experiment has to be defined. Note that this is a dummy example, which contains limited reasonable code. It is meant to show the core functionality of the PyExperimenter. \n",
				"\n",
				"The method is called with the parameters, i.e. `keyfields`, of a database entry. The results are meant to be processed to be written into the database, i.e. as `resultfields`. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"id": "gHr-IN2gBe8V"
			},
			"outputs": [],
			"source": [
				"import os\n",
				"import random\n",
				"\n",
				"import numpy as np\n",
				"from sklearn.datasets import load_iris\n",
				"from sklearn.model_selection import cross_validate\n",
				"from sklearn.pipeline import make_pipeline\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"from sklearn.svm import SVC\n",
				"\n",
				"from py_experimenter.experimenter import PyExperimenter\n",
				"from py_experimenter.result_processor import ResultProcessor\n",
				"\n",
				"from time import sleep\n",
				"from random import randint\n",
				"\n",
				"def run_svm(parameters: dict, result_processor: ResultProcessor, custom_config: dict):\n",
				"    sleep(randint(0,5))\n",
				"    seed = parameters['seed']\n",
				"    random.seed(seed)\n",
				"    np.random.seed(seed)\n",
				"\n",
				"    data = load_iris()\n",
				"\n",
				"    X = data.data\n",
				"    y = data.target\n",
				"\n",
				"    # Create Support Vector Machine with parameters dependent on the kernel\n",
				"    kernel = parameters['kernel']\n",
				"    if kernel == 'linear':\n",
				"        svc = SVC(kernel=parameters['kernel'])\n",
				"    elif kernel == 'poly':\n",
				"        svc = SVC(kernel=parameters['kernel'], gamma=parameters['gamma'], coef0=parameters['coef0'], degree=parameters['degree'])\n",
				"    elif kernel == 'rbf':\n",
				"        svc = SVC(kernel=parameters['kernel'], gamma=parameters['gamma'])\n",
				"\n",
				"    svc = SVC()\n",
				"\n",
				"    model = make_pipeline(StandardScaler(), svc)  \n",
				"\n",
				"    if parameters['dataset'] != 'iris':\n",
				"        raise ValueError(\"Example error\")\n",
				"\n",
				"    scores = cross_validate(model, X, y, \n",
				"        cv=parameters['cross_validation_splits'],\n",
				"        scoring=('accuracy', 'f1_micro'),\n",
				"        return_train_score=True\n",
				"    )\n",
				"    \n",
				"    result_processor.process_results({\n",
				"        'train_f1': np.mean(scores['train_f1_micro']),\n",
				"        'train_accuracy': np.mean(scores['train_accuracy'])\n",
				"    })\n",
				"\n",
				"    result_processor.process_results({\n",
				"        'test_f1': np.mean(scores['test_f1_micro']),\n",
				"        'test_accuracy': np.mean(scores['test_accuracy'])})"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "Sa6mN98NBua-"
			},
			"source": [
				"## Executing PyExperimenter\n",
				"\n",
				"The actual execution of the PyExperimenter is done in multiple steps. \n",
				"\n",
				"### Initialize PyExperimenter\n",
				"The PyExperimenter is initialized with the previously created configuration file. Additionally, `PyExperimenter` is given a `name`, i.e. job id, which is especially useful for parallel executions of multiple experiments on HPC. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "EFdaTyYQ-yqa"
			},
			"outputs": [],
			"source": [
				"from py_experimenter.experimenter import PyExperimenter\n",
				"\n",
				"experimenter = PyExperimenter(experiment_configuration_file_path=experiment_configuration_file_path, name=\"SVM_experimenter_01\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "tdLXOI7eFhBh"
			},
			"source": [
				"### Fill Table\n",
				"\n",
				"The table is filled programmatically using the  `fill_table_from_combination()` method. We first generate the fixed parameter combinations for each kernel of the SVM in the first three lines.\n",
				"* For the `rbf` kernel, we need to set values for the `gamma` parameter. The degree and `coef0` parameter are not present in this kernel, so we set these to `'nan'`.\n",
				"* For the `poly` kernel, we need to set the `gamma`, the degree as well as the `coef0` parameter.\n",
				"* For the `linear` kernel, we do not need to set any parameters, so all of them are set to `'nan'`.\n",
				"\n",
				"Afterwards, we combine these with the seed, the dataset and the cross_validation_splits parameters, which are present for all experiment runs. Thus, these are not set unconditionally."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "tdLXOI7eFhBh"
			},
			"source": [
				" \n",
				"\n",
				"Note that the table can easily be obtained as `pandas.Dataframe` via `experimenter.get_table()`."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 457
				},
				"id": "5DJlSHO3-2-v",
				"outputId": "447580e6-6a16-42ca-c44b-48a12829af91"
			},
			"outputs": [],
			"source": [
				"# Create parameter configurations for each kernel\n",
				"combinations = [{'kernel': 'rbf', 'gamma': gamma, 'degree':'nan', 'coef0':'nan'} for gamma in ['0.1','0.3']]\n",
				"combinations += [{'kernel': 'poly', 'gamma': gamma, 'degree': degree, 'coef0': coef0} for gamma in ['0.1','0.3'] for degree in ['3','4'] for coef0 in ['0.0', '0.1']]\n",
				"combinations += [{'kernel': 'linear','gamma': 'nan', 'degree':'nan', 'coef0':'nan'}]\n",
				"\n",
				"# Fill experimenter\n",
				"experimenter.fill_table_from_combination(parameters={'seed': ['1', '2', '3', '4', '5'], \n",
				"'dataset': ['iris'],\n",
				"'cross_validation_splits': ['5'] },\n",
				"fixed_parameter_combinations=combinations)\n",
				"\n",
				"# showing database table\n",
				"experimenter.get_table()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "jMGyvpTqFklu"
			},
			"source": [
				"### Execute PyExperimenter\n",
				"All experiments are executed one after the other by the same `PyExperimenter` due to `max_experiments=-1`. If just a single one or a predifined number of experiments should be executed, the `-1` has to be replaced by the according amount. The `random_order` is especially important in case of parallel execution of multiple `PyExperimenter`, e.g. when doing it on a HPC, to avoid collusions of accessing the same row of the table. \n",
				"\n",
				"The first parameter, i.e. `run_svm`, relates to the actual method that should be executed with the given keyfields of the table. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 1000
				},
				"id": "cDsuIw4M_AyY",
				"outputId": "d242da6f-1c9e-421b-f916-694c1a98ba95"
			},
			"outputs": [],
			"source": [
				"experimenter.execute(run_svm, max_experiments=-1, random_order=True)\n",
				"\n",
				"# showing database table\n",
				"experimenter.get_table() "
			]
		}
	],
	"metadata": {
		"colab": {
			"collapsed_sections": [],
			"provenance": []
		},
		"kernelspec": {
			"display_name": "Python 3.9.13 ('pyexperimenter')",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.13"
		},
		"vscode": {
			"interpreter": {
				"hash": "71187fe867589ed677ffb94266446485dc39ee78e473b070f8172b1f4c8ff4aa"
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
